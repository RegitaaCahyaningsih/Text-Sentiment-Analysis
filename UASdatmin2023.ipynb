{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from NLP_Models import TextMining as tm\n",
    "from NLP_Models import openewfile as of\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocecing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanningtext(data,sentiment = True):\n",
    "    fSlang = of.openfile(path = './NLP_Models/slangword')\n",
    "    bahasa = 'id'\n",
    "    stops, lemmatizer, tokenizer = tm.LoadStopWords(bahasa, sentiment = sentiment)\n",
    "    sw=open(fSlang,encoding='utf-8', errors ='ignore', mode='r');SlangS=sw.readlines();sw.close()\n",
    "    SlangS = {slang.strip().split(':')[0]:slang.strip().split(':')[1] for slang in SlangS}\n",
    "\n",
    "    tqdm.pandas()\n",
    "    \n",
    "    data['text'] = data['text'].astype('str')\n",
    "    data['text'] = data['text'].str.lower()\n",
    "    data = data[~data.text.str.contains('unavailable')]\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('CLEANING DATA TEXT IS PROCESSING')\n",
    "    data['cleaned_text'] = data['text'].progress_apply(lambda x : tm.cleanText(x,fix=SlangS, pattern2 = True, lang = bahasa, lemma=lemmatizer, tokenizer=tokenizer, stops = stops, symbols_remove = True, numbers_remove = True, hashtag_remove=False, min_charLen = 3))\n",
    "    print('CLEANING PROCESS IS DONE')\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('HANDLING NEGATION IS PROCESSING')\n",
    "    data['cleaned_text'] = data['cleaned_text'].progress_apply(lambda x : tm.handlingnegation(x))\n",
    "    print('HANDLING NEGATION IS DONE')\n",
    "    data = data[data['cleaned_text'].notna()]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprosecing data\n",
    "def dataPreparingandProcesing(path_data_negative, path_data_positive):\n",
    "    with open(f'{path_data_negative}', 'r', encoding='utf-8') as file:\n",
    "        dataNegative = json.load(file)\n",
    "\n",
    "    with open(f'{path_data_positive}', 'r', encoding='utf-8') as file:\n",
    "        dataPositive = json.load(file)\n",
    "\n",
    "    dfNegative, dfPositive = pd.json_normalize(dataNegative).iloc[0:200], pd.json_normalize(dataPositive).iloc[0:200]\n",
    "    df = pd.concat([dfNegative,dfPositive])\n",
    "    df = df[['text', 'Label']]\n",
    "    df = cleanningtext(df,sentiment = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_models(X_train, X_test, y_train, y_test, vectorizer, model_path, tokenizer_path):\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('TRAINING MODEL IS PROCESSING')\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', vectorizer),\n",
    "        ('clf', SVC(probability=True))\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'clf__C': [1, 10, 100],  # Misalnya, tambahkan lebih banyak nilai atau tambah beberapa hyperparameter lainnya\n",
    "        'clf__gamma': [0.1, 0.01]  # Misalnya, tambahkan lebih banyak nilai atau tambah beberapa hyperparameter lainnya\n",
    "    }\n",
    "\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score), #sklearn/matriks\n",
    "        'precision': make_scorer(precision_score, average='micro', zero_division=1), #ANDA BISA UBAH DISINI (MICRO/MACRO)\n",
    "        'recall': make_scorer(recall_score, average='micro', zero_division=1), #ANDA BISA UBAH DISINI (MICRO/MACRO)\n",
    "        'f1_score': make_scorer(f1_score, average='micro', zero_division=1) #ANDA BISA UBAH DISINI (MICRO/MACRO)\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=parameters, scoring=scoring, cv=5,refit='f1_score', return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('TRAIN MODEL IS DONE')\n",
    "    metrics_score_each_fold = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('EVALUATING MODEL IS PROCESSING')\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('EVALUATING MODEL IS DONE')\n",
    "\n",
    "    with open(f'{model_path}'+'/'+'best_model.pkl', 'wb') as model_file:\n",
    "        pickle.dump(best_model, model_file)\n",
    "\n",
    "    with open(f'{tokenizer_path}'+'/'+'tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "        pickle.dump(vectorizer, tokenizer_file)\n",
    "\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('MODEL AND TOKENIZER HAVE BEEN SAVED | ALL PROCESS ARE DONE')\n",
    "    return {'metrics_train': metrics_score_each_fold, 'best_model_parms': best_model, 'metrics_test': report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrixtermfreq(data):\n",
    "    vectorizer = TfidfVectorizer(max_df=0.9, min_df=0.1) #KALIAN HARUS PAHAM MAKSUD DARI max_df dan min_df. Dan boleh kalian ganti parameter ini\n",
    "    tfs = vectorizer.fit_transform(data)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    df = pd.DataFrame(tfs.todense(), columns=feature_names)\n",
    "    return df, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "CLEANING DATA TEXT IS PROCESSING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:00<00:00, 1951.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANING PROCESS IS DONE\n",
      "------------------------------------------------------------------------------------\n",
      "HANDLING NEGATION IS PROCESSING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:00<00:00, 80231.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HANDLING NEGATION IS DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Data yang digunakan untuk proses pelatihan dan pengujian\n",
      "\n",
      "\n",
      "                                                  text     Label  \\\n",
      "0    kamu tau ga kmaren pas timnas main suporter in...  negative   \n",
      "1                                     viking anjing!!!  negative   \n",
      "2          ke 6 viking pernah digigit anjing polisi ðŸ˜‹ðŸ˜  negative   \n",
      "3    mentang-mentang goblok gratis diborong semua j...  negative   \n",
      "4    manusia dijaga daripada bodoh anjing..polis ja...  negative   \n",
      "..                                                 ...       ...   \n",
      "195  @thisjwoopuppies bangga banget mau nangiss dia...  positive   \n",
      "196  seneng banget tl aku penuh sama ucapan jungwoo...  positive   \n",
      "197  untuk ara dimasa depan, kamu hebat raa bisa sa...  positive   \n",
      "198  aku bangga sama aku karena berhasil healing, a...  positive   \n",
      "199  satu lagi, tau nggak kalo kamu tuh hebat bange...  positive   \n",
      "\n",
      "                                          cleaned_text  \n",
      "0    kamu tahu tidak negxkemarin pas timnas main su...  \n",
      "1                                       viking anjing   \n",
      "2                    viking pernah gigit anjing polisi  \n",
      "3    mentang mentang goblok gratis borong semua jan...  \n",
      "4    manusia jaga negxdaripada bodoh anjing polis j...  \n",
      "..                                                 ...  \n",
      "195             bangga negxmau nangiss dia keren hebat  \n",
      "196  neng aku penuh sama ucap jungwoo keren bangga ...  \n",
      "197  untuk ara masa depan kamu hebat raa bisa sampa...  \n",
      "198  aku bangga negxsama aku karena hasil healing a...  \n",
      "199  satu lagi tahu tidak negxkalau kamu tuh hebat ...  \n",
      "\n",
      "[400 rows x 3 columns]\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Term-Matrix hasil TF-IDF\n",
      "\n",
      "\n",
      "          aku    anjing    bangga      bisa     hebat       ini  itu  \\\n",
      "0    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
      "1    0.000000  0.653676  0.000000  0.000000  0.000000  0.000000  0.0   \n",
      "2    0.000000  0.000000  0.159295  0.296472  0.156369  0.496670  0.0   \n",
      "3    0.000000  0.000000  0.205708  0.000000  0.201929  0.000000  0.0   \n",
      "4    0.000000  0.000000  0.352392  0.000000  0.345917  0.000000  0.0   \n",
      "..        ...       ...       ...       ...       ...       ...  ...   \n",
      "315  0.000000  0.418065  0.000000  0.000000  0.000000  0.000000  0.0   \n",
      "316  0.000000  0.932941  0.000000  0.000000  0.000000  0.000000  0.0   \n",
      "317  0.151036  0.000000  0.104032  0.000000  0.102121  0.000000  0.0   \n",
      "318  0.000000  0.000000  0.217900  0.405545  0.213897  0.339697  0.0   \n",
      "319  0.265303  0.188343  0.000000  0.000000  0.000000  0.000000  0.0   \n",
      "\n",
      "         jadi    kalian      kamu     keren  negxsama       nya      sama  \\\n",
      "0    0.000000  0.000000  0.294453  0.000000  0.000000  0.000000  0.386928   \n",
      "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2    0.000000  0.000000  0.610376  0.000000  0.232575  0.000000  0.000000   \n",
      "3    0.376238  0.000000  0.000000  0.202675  0.000000  0.305553  0.345253   \n",
      "4    0.000000  0.000000  0.000000  0.694391  0.000000  0.523433  0.000000   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "315  0.000000  0.768741  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "316  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "317  0.000000  0.000000  0.930120  0.102498  0.151890  0.154527  0.000000   \n",
      "318  0.000000  0.412964  0.000000  0.214687  0.000000  0.000000  0.365716   \n",
      "319  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.920107   \n",
      "\n",
      "         saya     semua     sudah     tidak    viking  \n",
      "0    0.000000  0.873833  0.000000  0.000000  0.000000  \n",
      "1    0.000000  0.000000  0.000000  0.000000  0.756774  \n",
      "2    0.232575  0.000000  0.279665  0.237999  0.000000  \n",
      "3    0.000000  0.000000  0.722298  0.000000  0.000000  \n",
      "4    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "315  0.000000  0.000000  0.000000  0.000000  0.484003  \n",
      "316  0.000000  0.000000  0.000000  0.000000  0.360029  \n",
      "317  0.000000  0.000000  0.182643  0.000000  0.000000  \n",
      "318  0.000000  0.412964  0.000000  0.325559  0.000000  \n",
      "319  0.000000  0.000000  0.000000  0.000000  0.218048  \n",
      "\n",
      "[320 rows x 19 columns]\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "TRAINING MODEL IS PROCESSING\n",
      "------------------------------------------------------------------------------------\n",
      "TRAIN MODEL IS DONE\n",
      "------------------------------------------------------------------------------------\n",
      "EVALUATING MODEL IS PROCESSING\n",
      "------------------------------------------------------------------------------------\n",
      "EVALUATING MODEL IS DONE\n",
      "------------------------------------------------------------------------------------\n",
      "MODEL AND TOKENIZER HAVE BEEN SAVED | ALL PROCESS ARE DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "MODEL PERFORMANCE ON GRID-SEARCH CV\n",
      "\n",
      "\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_clf__C  \\\n",
      "0       0.015184  9.984705e-04         0.007223    7.810698e-04            1   \n",
      "1       0.021800  7.788905e-04         0.007779    7.466461e-04            1   \n",
      "2       0.011817  3.027680e-04         0.007980    5.722046e-07           10   \n",
      "3       0.013402  8.292517e-04         0.007424    4.596392e-04           10   \n",
      "4       0.010372  7.979275e-04         0.007612    5.176195e-04          100   \n",
      "5       0.010970  4.422006e-07         0.007581    4.893188e-04          100   \n",
      "\n",
      "  param_clf__gamma                               params  split0_test_accuracy  \\\n",
      "0              0.1     {'clf__C': 1, 'clf__gamma': 0.1}              0.968750   \n",
      "1             0.01    {'clf__C': 1, 'clf__gamma': 0.01}              0.921875   \n",
      "2              0.1    {'clf__C': 10, 'clf__gamma': 0.1}              1.000000   \n",
      "3             0.01   {'clf__C': 10, 'clf__gamma': 0.01}              0.968750   \n",
      "4              0.1   {'clf__C': 100, 'clf__gamma': 0.1}              1.000000   \n",
      "5             0.01  {'clf__C': 100, 'clf__gamma': 0.01}              1.000000   \n",
      "\n",
      "   split1_test_accuracy  split2_test_accuracy  ...  mean_test_f1_score  \\\n",
      "0              0.968750              1.000000  ...            0.971875   \n",
      "1              0.921875              0.984375  ...            0.950000   \n",
      "2              0.968750              1.000000  ...            0.981250   \n",
      "3              0.968750              1.000000  ...            0.971875   \n",
      "4              0.968750              1.000000  ...            0.984375   \n",
      "5              0.968750              1.000000  ...            0.984375   \n",
      "\n",
      "   std_test_f1_score  rank_test_f1_score  split0_train_f1_score  \\\n",
      "0           0.015309                   4               0.964844   \n",
      "1           0.025000                   6               0.957031   \n",
      "2           0.015309                   3               0.996094   \n",
      "3           0.015309                   4               0.968750   \n",
      "4           0.013975                   1               0.996094   \n",
      "5           0.013975                   1               0.992188   \n",
      "\n",
      "   split1_train_f1_score  split2_train_f1_score  split3_train_f1_score  \\\n",
      "0               0.984375               0.976562               0.972656   \n",
      "1               0.960938               0.937500               0.949219   \n",
      "2               0.988281               0.996094               0.992188   \n",
      "3               0.984375               0.976562               0.972656   \n",
      "4               1.000000               0.996094               0.996094   \n",
      "5               0.992188               0.988281               0.996094   \n",
      "\n",
      "   split4_train_f1_score  mean_train_f1_score  std_train_f1_score  \n",
      "0               0.976562             0.975000            0.006347  \n",
      "1               0.957031             0.952344            0.008341  \n",
      "2               0.988281             0.992188            0.003494  \n",
      "3               0.976562             0.975781            0.005182  \n",
      "4               0.996094             0.996875            0.001563  \n",
      "5               0.988281             0.991406            0.002923  \n",
      "\n",
      "[6 rows x 67 columns]\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "BEST MODEL CONFIGURATION\n",
      "\n",
      "\n",
      "Pipeline(steps=[('tfidf', TfidfVectorizer(max_df=0.9, min_df=0.1)),\n",
      "                ('clf', SVC(C=100, gamma=0.1, probability=True))])\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "MODEL PERFORMANCE ON TEST DATA\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        44\n",
      "    positive       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    path_data_negative, path_data_positive = 'C:/Users/Dell/Desktop/blajar ngoding/datmin baru/DATASET/negative.json', 'C:/Users/Dell/Desktop/blajar ngoding/datmin baru/DATASET/positive.json'\n",
    "    df = dataPreparingandProcesing(path_data_negative, path_data_positive)\n",
    "\n",
    "    print('\\n'*3)\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('Data yang digunakan untuk proses pelatihan dan pengujian')\n",
    "    print('\\n'*1)\n",
    "    print(df)\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['Label'], test_size=0.2, random_state=42)\n",
    "    matrixTermFreq =  matrixtermfreq(X_train)\n",
    "    vectorizer, term_matrix = matrixTermFreq[1], matrixTermFreq[0]\n",
    "    \n",
    "    print('\\n'*3)\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('Term-Matrix hasil TF-IDF')\n",
    "    print('\\n'*1)\n",
    "    print(term_matrix)\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    \n",
    "    print('\\n'*3)\n",
    "    training_report = training_models(X_train, X_test, y_train, y_test, vectorizer, 'C:/Users/Dell/Desktop/blajar ngoding/datmin baru/MODEL', 'C:/Users/Dell/Desktop/blajar ngoding/datmin baru/TOKENIZER')\n",
    "\n",
    "    print('\\n'*3)\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('MODEL PERFORMANCE ON GRID-SEARCH CV')\n",
    "    print('\\n'*1)\n",
    "    print(training_report['metrics_train'])\n",
    "    training_report['metrics_train'].to_csv('C:/Users/Dell/Desktop/blajar ngoding/datmin baru/METRICS/gridSearchcv.csv')\n",
    "    print('\\n'*1)\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('BEST MODEL CONFIGURATION')\n",
    "    print('\\n'*1)\n",
    "    print(training_report['best_model_parms'])\n",
    "    print('\\n'*1)\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('MODEL PERFORMANCE ON TEST DATA')\n",
    "    print('\\n'*1)\n",
    "    print(training_report['metrics_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        44\n",
      "    positive       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#performa model pertama\n",
    "print(training_report['metrics_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98125"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['Label'], test_size=0.2, random_state=42)\n",
    "#tf idf\n",
    "matrixTermFreq =  matrixtermfreq(X_train)\n",
    "vectorizer, term_matrix = matrixTermFreq[1], matrixTermFreq[0]\n",
    "#classify with SVC\n",
    "clf = SVC(kernel='linear', C=1, random_state=19, probability=True)\n",
    "y_train_tfidf = y_train.apply(lambda x: 1 if x == 'positive' else 0)\n",
    "clf.fit(matrixTermFreq[0], y_train_tfidf)\n",
    "# CV Score from classify with SVC\n",
    "scores2 = cross_val_score(clf, matrixTermFreq[0], y_train, cv=5).mean()\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Hasil performa model\n",
    "precision_values = [1.00, 1.00]\n",
    "recall_values = [1.00, 1.00]\n",
    "f1_score_values = [1.00, 1.00]\n",
    "\n",
    "# Membuat DataFrame dari hasil performa\n",
    "data2 = {'Precision': precision_values, 'Recall': recall_values, 'F1-Score': f1_score_values}\n",
    "data2 = pd.DataFrame(data2)\n",
    "\n",
    "# Visualisasi dengan boxplot\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.boxplot(data=data2)\n",
    "plt.title('Boxplot Model Performance Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1.1)  # Skala sumbu y dari 0 hingga 1.1 untuk memastikan visualisasi yang tepat\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aku</th>\n",
       "      <th>anda</th>\n",
       "      <th>anjing</th>\n",
       "      <th>bangga</th>\n",
       "      <th>hebat</th>\n",
       "      <th>ini</th>\n",
       "      <th>kalau</th>\n",
       "      <th>kalian</th>\n",
       "      <th>kamu</th>\n",
       "      <th>keren</th>\n",
       "      <th>negxsama</th>\n",
       "      <th>nya</th>\n",
       "      <th>sama</th>\n",
       "      <th>saya</th>\n",
       "      <th>semangat</th>\n",
       "      <th>semua</th>\n",
       "      <th>sudah</th>\n",
       "      <th>tidak</th>\n",
       "      <th>viking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192067</td>\n",
       "      <td>0.190648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487677</td>\n",
       "      <td>0.192067</td>\n",
       "      <td>0.269258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.180691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130254</td>\n",
       "      <td>0.129292</td>\n",
       "      <td>0.381551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661457</td>\n",
       "      <td>0.130254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473827</td>\n",
       "      <td>0.240997</td>\n",
       "      <td>0.225841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096585</td>\n",
       "      <td>0.287614</td>\n",
       "      <td>0.141462</td>\n",
       "      <td>0.178701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858334</td>\n",
       "      <td>0.096585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167464</td>\n",
       "      <td>0.286171</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403807</td>\n",
       "      <td>0.839710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169869</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.559260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201576</td>\n",
       "      <td>0.200087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511822</td>\n",
       "      <td>0.201576</td>\n",
       "      <td>0.282589</td>\n",
       "      <td>0.313253</td>\n",
       "      <td>0.354940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170540</td>\n",
       "      <td>0.169281</td>\n",
       "      <td>0.499560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.649528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295691</td>\n",
       "      <td>0.252646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          aku  anda    anjing    bangga     hebat       ini     kalau  kalian  \\\n",
       "0    0.000000   0.0  1.000000  0.000000  0.000000  0.000000  0.000000     0.0   \n",
       "1    0.000000   0.0  0.000000  0.192067  0.190648  0.000000  0.000000     0.0   \n",
       "2    0.000000   0.0  0.636571  0.000000  0.000000  0.000000  0.000000     0.0   \n",
       "3    0.000000   0.0  0.531182  0.000000  0.000000  0.000000  0.000000     0.0   \n",
       "4    0.180691   0.0  0.000000  0.130254  0.129292  0.381551  0.000000     0.0   \n",
       "..        ...   ...       ...       ...       ...       ...       ...     ...   \n",
       "155  0.000000   0.0  0.000000  0.096585  0.287614  0.141462  0.178701     0.0   \n",
       "156  0.000000   0.0  0.636571  0.000000  0.000000  0.000000  0.000000     0.0   \n",
       "157  0.000000   0.0  0.113817  0.000000  0.000000  0.000000  0.212152     0.0   \n",
       "158  0.559260   0.0  0.000000  0.201576  0.200087  0.000000  0.000000     0.0   \n",
       "159  0.000000   0.0  0.000000  0.170540  0.169281  0.499560  0.000000     0.0   \n",
       "\n",
       "         kamu     keren  negxsama       nya      sama      saya  semangat  \\\n",
       "0    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    0.487677  0.192067  0.269258  0.000000  0.676392  0.000000  0.349341   \n",
       "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.783779  0.000000   \n",
       "4    0.661457  0.130254  0.000000  0.000000  0.000000  0.000000  0.473827   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "155  0.858334  0.096585  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "156  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "157  0.000000  0.000000  0.000000  0.000000  0.403807  0.839710  0.000000   \n",
       "158  0.511822  0.201576  0.282589  0.313253  0.354940  0.000000  0.000000   \n",
       "159  0.649528  0.000000  0.239080  0.000000  0.000000  0.249780  0.000000   \n",
       "\n",
       "        semua     sudah     tidak    viking  \n",
       "0    0.000000  0.000000  0.000000  0.000000  \n",
       "1    0.000000  0.000000  0.000000  0.000000  \n",
       "2    0.000000  0.000000  0.000000  0.771219  \n",
       "3    0.000000  0.000000  0.000000  0.321769  \n",
       "4    0.240997  0.225841  0.000000  0.000000  \n",
       "..        ...       ...       ...       ...  \n",
       "155  0.000000  0.167464  0.286171  0.000000  \n",
       "156  0.000000  0.000000  0.000000  0.771219  \n",
       "157  0.212152  0.000000  0.169869  0.000000  \n",
       "158  0.000000  0.000000  0.000000  0.000000  \n",
       "159  0.000000  0.295691  0.252646  0.000000  \n",
       "\n",
       "[160 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kamu tau ga kmaren pas timnas main suporter in...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kamu tahu tidak negxkemarin pas timnas main su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>viking anjing!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>viking anjing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ke 6 viking pernah digigit anjing polisi ðŸ˜‹ðŸ˜</td>\n",
       "      <td>negative</td>\n",
       "      <td>viking pernah gigit anjing polisi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mentang-mentang goblok gratis diborong semua j...</td>\n",
       "      <td>negative</td>\n",
       "      <td>mentang mentang goblok gratis borong semua jan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manusia dijaga daripada bodoh anjing..polis ja...</td>\n",
       "      <td>negative</td>\n",
       "      <td>manusia jaga negxdaripada bodoh anjing polis j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>pas gua peringkat 30 dari 37 di sekolah dia ng...</td>\n",
       "      <td>positive</td>\n",
       "      <td>pas saya peringkat dari sekolah dia bicara beg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tadi pagi laporan hari ini dia nervous huhu ga...</td>\n",
       "      <td>positive</td>\n",
       "      <td>tadi pagi lapor hari ini dia nervous huhu tida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>jaehyun u did well nak, huhu sayang pol sama j...</td>\n",
       "      <td>positive</td>\n",
       "      <td>jaehyun kamu did well anak huhu sayang pol sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>jujur aja sama sekali nggak ada ^__^ pacarku u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>jujur saja sama sekali tidak negxada pacar sud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@valiant_eva kaaaak... kakak ada suami, berbag...</td>\n",
       "      <td>positive</td>\n",
       "      <td>kaak kakak ada suami bagi sama suami kakak jan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     Label  \\\n",
       "0   kamu tau ga kmaren pas timnas main suporter in...  negative   \n",
       "1                                    viking anjing!!!  negative   \n",
       "2         ke 6 viking pernah digigit anjing polisi ðŸ˜‹ðŸ˜  negative   \n",
       "3   mentang-mentang goblok gratis diborong semua j...  negative   \n",
       "4   manusia dijaga daripada bodoh anjing..polis ja...  negative   \n",
       "..                                                ...       ...   \n",
       "95  pas gua peringkat 30 dari 37 di sekolah dia ng...  positive   \n",
       "96  tadi pagi laporan hari ini dia nervous huhu ga...  positive   \n",
       "97  jaehyun u did well nak, huhu sayang pol sama j...  positive   \n",
       "98  jujur aja sama sekali nggak ada ^__^ pacarku u...  positive   \n",
       "99  @valiant_eva kaaaak... kakak ada suami, berbag...  positive   \n",
       "\n",
       "                                         cleaned_text  \n",
       "0   kamu tahu tidak negxkemarin pas timnas main su...  \n",
       "1                                      viking anjing   \n",
       "2                   viking pernah gigit anjing polisi  \n",
       "3   mentang mentang goblok gratis borong semua jan...  \n",
       "4   manusia jaga negxdaripada bodoh anjing polis j...  \n",
       "..                                                ...  \n",
       "95  pas saya peringkat dari sekolah dia bicara beg...  \n",
       "96  tadi pagi lapor hari ini dia nervous huhu tida...  \n",
       "97  jaehyun kamu did well anak huhu sayang pol sam...  \n",
       "98  jujur saja sama sekali tidak negxada pacar sud...  \n",
       "99  kaak kakak ada suami bagi sama suami kakak jan...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Kata untuk Kategori 0: [('anjing', 111), ('viking', 69), ('tidak', 21), ('bonek', 18), ('saya', 18), ('nya', 13), ('sama', 11), ('anda', 11), ('kalau', 11), ('main', 10)]\n",
      "'\n",
      "Top 10 Kata untuk Kategori 1: [('kamu', 156), ('keren', 111), ('hebat', 108), ('bangga', 102), ('aku', 70), ('saya', 50), ('negxsama', 46), ('sudah', 36), ('ini', 35), ('nya', 35)]\n"
     ]
    }
   ],
   "source": [
    "# Tokenisasi teks\n",
    "df['tokens'] = df['cleaned_text'].apply(word_tokenize)\n",
    "df['kategori'] = df['Label'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "# Pisahkan data berdasarkan kategori (misalnya, kategori 0 dan 1)\n",
    "kategori_0 = df[df['kategori'] == 0]['tokens']\n",
    "kategori_1 = df[df['kategori'] == 1]['tokens']\n",
    "\n",
    "# Hitung frekuensi kata untuk masing-masing kategori\n",
    "freq_kat_0 = FreqDist([word for tokens in kategori_0 for word in tokens])\n",
    "freq_kat_1 = FreqDist([word for tokens in kategori_1 for word in tokens])\n",
    "\n",
    "# Ambil 10 kata dengan frekuensi tertinggi untuk masing-masing kategori\n",
    "top_10_kat_0 = freq_kat_0.most_common(10)\n",
    "top_10_kat_1 = freq_kat_1.most_common(10)\n",
    "\n",
    "print(\"Top 10 Kata untuk Kategori 0:\", top_10_kat_0)\n",
    "print('\\'')\n",
    "print(\"Top 10 Kata untuk Kategori 1:\", top_10_kat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitung_ngram(token, n):\n",
    "    n_gram=ngrams(token, n)\n",
    "    return FreqDist(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Unigram untuk Kategori 0: [(('anjing',), 111), (('viking',), 69), (('tidak',), 21), (('bonek',), 18), (('saya',), 18), (('nya',), 13), (('sama',), 11), (('anda',), 11), (('kalau',), 11), (('main',), 10)]\n",
      "/\n",
      "Top 10 Bigram untuk Kategori 0: [(('viking', 'anjing'), 46), (('anjing', 'bonek'), 6), (('bonek', 'jancok'), 6), (('anjing', 'anjing'), 6), (('anjing', 'viking'), 5), (('bilang', 'viking'), 4), (('tidak', 'negxsemua'), 3), (('jancok', 'viking'), 3), (('anjing', 'lama'), 3), (('anjing', 'kita'), 3)]\n",
      "/\n",
      "Top 10 Trigram untuk Kategori 0: [(('viking', 'anjing', 'bonek'), 4), (('anjing', 'bonek', 'jancok'), 4), (('anjing', 'viking', 'anjing'), 4), (('viking', 'anjing', 'viking'), 3), (('bilang', 'viking', 'anjing'), 3), (('bonek', 'jancok', 'viking'), 3), (('jancok', 'viking', 'anjing'), 3), (('viking', 'anjing', 'lama'), 3), (('tidak', 'negxsemua', 'juga'), 2), (('viking', 'anjing', 'saya'), 2)]\n",
      "/\n",
      "Top 10 Unigram untuk Kategori 1: [(('kamu',), 156), (('keren',), 111), (('hebat',), 108), (('bangga',), 102), (('aku',), 70), (('saya',), 50), (('negxsama',), 46), (('sudah',), 36), (('ini',), 35), (('nya',), 35)]\n",
      "/\n",
      "Top 10 Bigram untuk Kategori 1: [(('bangga', 'negxsama'), 46), (('kamu', 'keren'), 30), (('kamu', 'hebat'), 25), (('aku', 'bangga'), 25), (('saya', 'bangga'), 22), (('hebat', 'kamu'), 18), (('negxsama', 'kamu'), 16), (('keren', 'hebat'), 14), (('keren', 'kamu'), 11), (('kamu', 'kamu'), 11)]\n",
      "/\n",
      "Top 10 Trigram untuk Kategori 1: [(('bangga', 'negxsama', 'kamu'), 16), (('kamu', 'hebat', 'kamu'), 16), (('aku', 'bangga', 'negxsama'), 15), (('saya', 'bangga', 'negxsama'), 13), (('hebat', 'kamu', 'keren'), 10), (('kamu', 'keren', 'kamu'), 9), (('keren', 'kamu', 'hebat'), 8), (('keren', 'aku', 'bangga'), 7), (('hebat', 'aku', 'bangga'), 6), (('oss', 'oss', 'oss'), 6)]\n"
     ]
    }
   ],
   "source": [
    "# Hitung frekuensi unigram, bigram, dan trigram untuk masing-masing kategori\n",
    "freq_unigram_kat_0 = hitung_ngram([word for tokens in kategori_0 for word in tokens], 1)\n",
    "freq_bigram_kat_0 = hitung_ngram([word for tokens in kategori_0 for word in tokens], 2)\n",
    "freq_trigram_kat_0 = hitung_ngram([word for tokens in kategori_0 for word in tokens], 3)\n",
    "\n",
    "freq_unigram_kat_1 = hitung_ngram([word for tokens in kategori_1 for word in tokens], 1)\n",
    "freq_bigram_kat_1 = hitung_ngram([word for tokens in kategori_1 for word in tokens], 2)\n",
    "freq_trigram_kat_1 = hitung_ngram([word for tokens in kategori_1 for word in tokens], 3)\n",
    "\n",
    "# Ambil 10 n-gram dengan frekuensi tertinggi untuk masing-masing kategori\n",
    "top_10_unigram_kat_0 = freq_unigram_kat_0.most_common(10)\n",
    "top_10_bigram_kat_0 = freq_bigram_kat_0.most_common(10)\n",
    "top_10_trigram_kat_0 = freq_trigram_kat_0.most_common(10)\n",
    "\n",
    "top_10_unigram_kat_1 = freq_unigram_kat_1.most_common(10)\n",
    "top_10_bigram_kat_1 = freq_bigram_kat_1.most_common(10)\n",
    "top_10_trigram_kat_1 = freq_trigram_kat_1.most_common(10)\n",
    "\n",
    "print(\"Top 10 Unigram untuk Kategori 0:\", top_10_unigram_kat_0)\n",
    "print('/')\n",
    "print(\"Top 10 Bigram untuk Kategori 0:\", top_10_bigram_kat_0)\n",
    "print('/')\n",
    "print(\"Top 10 Trigram untuk Kategori 0:\", top_10_trigram_kat_0)\n",
    "print('/')\n",
    "\n",
    "print(\"Top 10 Unigram untuk Kategori 1:\", top_10_unigram_kat_1)\n",
    "print('/')\n",
    "print(\"Top 10 Bigram untuk Kategori 1:\", top_10_bigram_kat_1)\n",
    "print('/')\n",
    "print(\"Top 10 Trigram untuk Kategori 1:\", top_10_trigram_kat_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241m.\u001b[39mdf[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      2\u001b[0m b\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "b = test.df[['cleaned_text', 'Label']]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = test.term_matrix\n",
    "b.twitter.isna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.training_report['metrics_test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16f92f66499f87d83466aaa09cc9adf887b790ef4c4eedd4adc62af74b04a8c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
